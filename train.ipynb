{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bittle Quadruped Locomotion Training\n",
    "\n",
    "Train a locomotion policy for the Bittle quadruped robot using Brax PPO, then export to ONNX and record a video.\n",
    "\n",
    "**Modes:**\n",
    "- **Test mode** (`TEST_MODE = True`): ~6 min on A100, minimal training for pipeline verification\n",
    "- **Full mode** (`TEST_MODE = False`): ~30 min on A100, production-quality policy\n",
    "\n",
    "**Outputs:** `outputs/policy.onnx` + `outputs/videos/latest_video.mp4`\n",
    "\n",
    "**Requirements:** Google Colab with a GPU runtime (A100 recommended). Go to Runtime > Change runtime type > GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GPU check & install dependencies\nimport subprocess, os\n\nresult = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\nif result.returncode != 0:\n    raise RuntimeError(\n        \"No GPU detected! Go to Runtime > Change runtime type > GPU, then restart.\"\n    )\nprint(result.stdout)\n\nGITHUB_TOKEN = \"\"  # @param {type:\"string\"}\nREPO = \"triton-droids/pupper-simulations\"\n\nif not os.path.exists(\"pupper-simulations\"):\n    if GITHUB_TOKEN:\n        !git clone https://{GITHUB_TOKEN}@github.com/{REPO}.git\n    else:\n        !git clone https://github.com/{REPO}.git\n    if not os.path.exists(\"pupper-simulations\"):\n        raise RuntimeError(\n            \"Clone failed. If the repo is private, set GITHUB_TOKEN above to a \"\n            \"GitHub personal access token with repo scope.\"\n        )\nelse:\n    print(\"Repository already cloned, skipping.\")\n\n%cd pupper-simulations\n!pip install -e .\n\nprint(\"\\n--- Installation complete ---\")\nprint(\"If you see dependency errors above, restart the runtime (Runtime > Restart runtime) and re-run this cell.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os, sys, warnings\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered in cast\")\n",
    "\n",
    "# Add locomotion/ to sys.path for bare imports (e.g. bittle_env, training_config)\n",
    "locomotion_dir = os.path.join(os.getcwd(), \"locomotion\")\n",
    "if locomotion_dir not in sys.path:\n",
    "    sys.path.insert(0, locomotion_dir)\n",
    "\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "assert any(d.platform == \"gpu\" for d in jax.devices()), \"No GPU visible to JAX!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODE = True  # @param {type:\"boolean\"}\n",
    "\n",
    "ONNX_OUTPUT = \"outputs/policy.onnx\"\n",
    "VIDEO_OUTPUT = \"outputs/videos/latest_video.mp4\"\n",
    "XML_PATH = \"locomotion/bittle_adapted_scene.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brax import envs\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from bittle_env import BittleEnv\n",
    "from training_config import TrainingConfig\n",
    "\n",
    "config = TrainingConfig(test_mode=TEST_MODE)\n",
    "mode = \"TEST\" if TEST_MODE else \"FULL\"\n",
    "print(f\"Training Bittle ({mode} mode) | {config.to_dict()}\")\n",
    "\n",
    "# Register environment (idempotent)\n",
    "if \"bittle\" not in envs._envs:\n",
    "    envs.register_environment(\"bittle\", BittleEnv)\n",
    "\n",
    "env = envs.get_environment(\"bittle\", xml_path=XML_PATH)\n",
    "\n",
    "# Collect rewards for plotting\n",
    "training_rewards = []\n",
    "training_steps = []\n",
    "\n",
    "def progress(step, metrics):\n",
    "    reward = float(metrics[\"eval/episode_reward\"])\n",
    "    training_steps.append(step)\n",
    "    training_rewards.append(reward)\n",
    "    print(f\"  Step {step:>10,} | Reward: {reward:.4f}\")\n",
    "\n",
    "make_policy, params, _ = ppo.train(\n",
    "    environment=env,\n",
    "    progress_fn=progress,\n",
    "    num_timesteps=config.num_timesteps,\n",
    "    num_evals=config.num_evals,\n",
    "    episode_length=config.episode_length,\n",
    "    num_envs=config.num_envs,\n",
    "    batch_size=config.batch_size,\n",
    "    unroll_length=config.unroll_length,\n",
    "    num_minibatches=config.num_minibatches,\n",
    "    num_updates_per_batch=config.num_updates_per_batch,\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining complete! Final reward: {training_rewards[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(training_steps, training_rewards, marker=\"o\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Episode Reward\")\n",
    "plt.title(f\"Training Curve ({mode} mode)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_export import export_policy_to_onnx\n",
    "\n",
    "os.makedirs(os.path.dirname(ONNX_OUTPUT), exist_ok=True)\n",
    "export_policy_to_onnx(params, ONNX_OUTPUT)\n",
    "\n",
    "size_kb = os.path.getsize(ONNX_OUTPUT) / 1024\n",
    "print(f\"ONNX model saved to {ONNX_OUTPUT} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_recorder import record_video\n",
    "\n",
    "record_video(env, make_policy, params, VIDEO_OUTPUT)\n",
    "\n",
    "size_kb = os.path.getsize(VIDEO_OUTPUT) / 1024\n",
    "print(f\"Video saved to {VIDEO_OUTPUT} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display video inline\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "with open(VIDEO_OUTPUT, \"rb\") as f:\n",
    "    video_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video width=\"640\" autoplay loop controls>\n",
    "  <source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(ONNX_OUTPUT)\n",
    "files.download(VIDEO_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}